{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Tiền xử lý dữ liệu bệnh tim\n",
        "\n",
        "Notebook này tập trung vào các bước tiền xử lý dữ liệu và trực quan hóa cho dự án phân tích bệnh tim.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cài đặt các thư viện cần thiết\n",
        "%pip install numpy pandas matplotlib seaborn scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import các thư viện cần thiết\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Cài đặt style cho biểu đồ\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('viridis')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "%matplotlib inline\n",
        "\n",
        "# Tạo thư mục để lưu trữ dữ liệu và hình ảnh\n",
        "if not os.path.exists('processed_data'):\n",
        "    os.makedirs('processed_data')\n",
        "if not os.path.exists('visualizations'):\n",
        "    os.makedirs('visualizations')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Đọc và khám phá dữ liệu\n",
        "\n",
        "Đọc các tập dữ liệu về bệnh tim từ nhiều nguồn khác nhau.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Định nghĩa hàm đọc và khám phá dữ liệu\n",
        "def load_and_explore_data(file_path):\n",
        "    \"\"\"\n",
        "    Đọc file dữ liệu CSV và hiển thị thông tin cơ bản\n",
        "    \"\"\"\n",
        "    print(f\"Đọc file: {file_path}\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    \n",
        "    print(f\"Kích thước dữ liệu: {df.shape}\")\n",
        "    print(\"\\nThông tin cơ bản:\")\n",
        "    print(df.info())\n",
        "    print(\"\\nThống kê mô tả:\")\n",
        "    display(df.describe())\n",
        "    print(\"\\nKiểm tra giá trị thiếu:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\n5 dòng đầu tiên:\")\n",
        "    display(df.head())\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tải dữ liệu từ Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Vui lòng tải lên tập dữ liệu bệnh tim (heart.csv, heart_disease_uci.csv và heart_cleveland_upload.csv)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Đọc và khám phá từng tập dữ liệu\n",
        "heart_df = load_and_explore_data('heart.csv')\n",
        "cleveland_df = load_and_explore_data('heart_cleveland_upload.csv')\n",
        "uci_df = load_and_explore_data('heart_disease_uci.csv')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Trực quan hóa dữ liệu\n",
        "\n",
        "Thực hiện các phân tích trực quan trên dữ liệu bằng biểu đồ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 2.1 Hiển thị phân bố các đặc trưng bằng Histogram\n",
        "\n",
        "def plot_histograms(df, dataset_name):\n",
        "    \"\"\"\n",
        "    Vẽ histogram cho các đặc trưng số\n",
        "    \"\"\"\n",
        "    # Lấy danh sách các cột số\n",
        "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    \n",
        "    # Tạo lưới biểu đồ\n",
        "    n_features = len(numeric_features)\n",
        "    n_cols = 3\n",
        "    n_rows = (n_features + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 5))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    # Vẽ histogram cho từng đặc trưng\n",
        "    for i, feature in enumerate(numeric_features):\n",
        "        sns.histplot(df[feature], bins=20, kde=True, ax=axes[i])\n",
        "        axes[i].set_title(f'Phân bố của {feature}')\n",
        "        axes[i].set_xlabel(feature)\n",
        "        axes[i].set_ylabel('Tần suất')\n",
        "    \n",
        "    # Ẩn các trục thừa\n",
        "    for i in range(n_features, len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(f'Phân bố các đặc trưng - {dataset_name}', fontsize=16, y=1.02)\n",
        "    plt.savefig(f'visualizations/{dataset_name}_histograms.png')\n",
        "    plt.show()\n",
        "\n",
        "# Vẽ histogram cho từng tập dữ liệu\n",
        "print(\"Biểu đồ Histogram cho tập dữ liệu Heart:\")\n",
        "plot_histograms(heart_df, 'heart')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Biểu đồ Histogram cho tập dữ liệu Cleveland:\")\n",
        "plot_histograms(cleveland_df, 'cleveland')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Biểu đồ Histogram cho tập dữ liệu UCI:\")\n",
        "plot_histograms(uci_df, 'uci')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 2.2 Phân tích mối quan hệ giữa các đặc trưng bằng Scatter Plot\n",
        "\n",
        "def plot_scatter_relationships(df, dataset_name):\n",
        "    \"\"\"\n",
        "    Vẽ scatter plots giữa các cặp đặc trưng quan trọng\n",
        "    \"\"\"\n",
        "    # Lựa chọn một số đặc trưng quan trọng\n",
        "    key_features = []\n",
        "    \n",
        "    # Xác định đặc trưng đích\n",
        "    target_col = 'target' if 'target' in df.columns else 'condition'\n",
        "    \n",
        "    # Xác định các đặc trưng số quan trọng dựa trên tập dữ liệu\n",
        "    if 'age' in df.columns and 'thalach' in df.columns:\n",
        "        key_features.append(('age', 'thalach'))\n",
        "    \n",
        "    if 'age' in df.columns and 'chol' in df.columns:\n",
        "        key_features.append(('age', 'chol'))\n",
        "        \n",
        "    if 'thalach' in df.columns and 'chol' in df.columns:\n",
        "        key_features.append(('thalach', 'chol'))\n",
        "    \n",
        "    if 'trestbps' in df.columns and 'chol' in df.columns:\n",
        "        key_features.append(('trestbps', 'chol'))\n",
        "    \n",
        "    if len(key_features) == 0:\n",
        "        print(f\"Không tìm thấy các cặp đặc trưng phù hợp trong tập dữ liệu {dataset_name}\")\n",
        "        return\n",
        "    \n",
        "    # Vẽ scatter plots\n",
        "    fig, axes = plt.subplots(1, len(key_features), figsize=(6*len(key_features), 5))\n",
        "    if len(key_features) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, (x_feature, y_feature) in enumerate(key_features):\n",
        "        sns.scatterplot(\n",
        "            data=df,\n",
        "            x=x_feature,\n",
        "            y=y_feature,\n",
        "            hue=target_col,\n",
        "            palette=['blue', 'red'],\n",
        "            alpha=0.7,\n",
        "            ax=axes[i]\n",
        "        )\n",
        "        axes[i].set_title(f'{y_feature} vs {x_feature}')\n",
        "        axes[i].set_xlabel(x_feature)\n",
        "        axes[i].set_ylabel(y_feature)\n",
        "        if i == len(key_features) - 1:  # Chỉ hiển thị legend cho biểu đồ cuối cùng\n",
        "            axes[i].legend(['Không bệnh', 'Bệnh tim'], title=target_col)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(f'Mối quan hệ giữa các đặc trưng - {dataset_name}', fontsize=16, y=1.05)\n",
        "    plt.savefig(f'visualizations/{dataset_name}_scatter_plots.png')\n",
        "    plt.show()\n",
        "\n",
        "# Vẽ scatter plots cho từng tập dữ liệu\n",
        "print(\"Biểu đồ Scatter cho tập dữ liệu Heart:\")\n",
        "plot_scatter_relationships(heart_df, 'heart')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Biểu đồ Scatter cho tập dữ liệu Cleveland:\")\n",
        "plot_scatter_relationships(cleveland_df, 'cleveland')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Biểu đồ Scatter cho tập dữ liệu UCI:\")\n",
        "plot_scatter_relationships(uci_df, 'uci')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 2.3 Phân tích tương quan bằng Heatmap\n",
        "\n",
        "def plot_correlation_matrix(df, dataset_name):\n",
        "    \"\"\"\n",
        "    Vẽ ma trận tương quan giữa các đặc trưng\n",
        "    \"\"\"\n",
        "    # Lấy các cột số để tính tương quan\n",
        "    numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
        "    \n",
        "    # Tính ma trận tương quan\n",
        "    corr = numeric_df.corr()\n",
        "    \n",
        "    # Vẽ heatmap\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    mask = np.triu(np.ones_like(corr, dtype=bool))  # Để chỉ hiển thị nửa dưới của ma trận\n",
        "    sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "                square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "    \n",
        "    plt.title(f'Ma trận tương quan - {dataset_name}', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'visualizations/{dataset_name}_correlation.png')\n",
        "    plt.show()\n",
        "    \n",
        "    # Tìm các cặp đặc trưng có tương quan cao\n",
        "    high_corr = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "    high_corr_pairs = [(corr.index[i], corr.columns[j], corr.iloc[i, j]) \n",
        "                      for i, j in zip(*np.where(np.abs(high_corr) > 0.5))]\n",
        "    \n",
        "    if high_corr_pairs:\n",
        "        print(f\"\\nCác cặp đặc trưng có tương quan cao (|r| > 0.5) trong tập dữ liệu {dataset_name}:\")\n",
        "        for feat1, feat2, corr_val in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True):\n",
        "            print(f\"- {feat1} và {feat2}: {corr_val:.3f}\")\n",
        "    else:\n",
        "        print(f\"\\nKhông có cặp đặc trưng nào có tương quan cao (|r| > 0.5) trong tập dữ liệu {dataset_name}\")\n",
        "\n",
        "# Vẽ ma trận tương quan cho từng tập dữ liệu\n",
        "print(\"Ma trận tương quan cho tập dữ liệu Heart:\")\n",
        "plot_correlation_matrix(heart_df, 'heart')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMa trận tương quan cho tập dữ liệu Cleveland:\")\n",
        "plot_correlation_matrix(cleveland_df, 'cleveland')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMa trận tương quan cho tập dữ liệu UCI:\")\n",
        "plot_correlation_matrix(uci_df, 'uci')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 2.4 Phân tích xu hướng bằng Line Chart\n",
        "\n",
        "def plot_line_charts(df, dataset_name):\n",
        "    \"\"\"\n",
        "    Vẽ biểu đồ đường phân tích xu hướng theo tuổi\n",
        "    \"\"\"\n",
        "    # Xác định biến đích\n",
        "    target_col = 'target' if 'target' in df.columns else 'condition'\n",
        "    \n",
        "    # Kiểm tra xem có cột tuổi không\n",
        "    if 'age' not in df.columns:\n",
        "        print(f\"Không tìm thấy cột tuổi trong tập dữ liệu {dataset_name}\")\n",
        "        return\n",
        "    \n",
        "    # Tạo các nhóm tuổi\n",
        "    df['age_group'] = pd.cut(df['age'], bins=range(30, 85, 5), right=False)\n",
        "    \n",
        "    # Tính tỉ lệ mắc bệnh theo từng nhóm tuổi\n",
        "    age_disease_rate = df.groupby('age_group')[target_col].mean().reset_index()\n",
        "    \n",
        "    # Vẽ biểu đồ đường\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(age_disease_rate['age_group'].astype(str), \n",
        "             age_disease_rate[target_col], \n",
        "             marker='o', \n",
        "             linewidth=2, \n",
        "             markersize=10)\n",
        "    \n",
        "    plt.title(f'Tỉ lệ mắc bệnh tim theo độ tuổi - {dataset_name}', fontsize=16)\n",
        "    plt.xlabel('Nhóm tuổi')\n",
        "    plt.ylabel('Tỉ lệ mắc bệnh tim')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'visualizations/{dataset_name}_age_disease_trend.png')\n",
        "    plt.show()\n",
        "    \n",
        "    # Nếu có dữ liệu về cholesterol, vẽ xu hướng theo cholesterol\n",
        "    if 'chol' in df.columns:\n",
        "        # Tạo các nhóm cholesterol\n",
        "        df['chol_group'] = pd.cut(df['chol'], bins=range(100, 601, 50), right=False)\n",
        "        \n",
        "        # Tính tỉ lệ mắc bệnh theo từng nhóm cholesterol\n",
        "        chol_disease_rate = df.groupby('chol_group')[target_col].mean().reset_index()\n",
        "        \n",
        "        # Vẽ biểu đồ đường\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(chol_disease_rate['chol_group'].astype(str), \n",
        "                chol_disease_rate[target_col], \n",
        "                marker='o', \n",
        "                linewidth=2,\n",
        "                color='red',\n",
        "                markersize=10)\n",
        "        \n",
        "        plt.title(f'Tỉ lệ mắc bệnh tim theo mức Cholesterol - {dataset_name}', fontsize=16)\n",
        "        plt.xlabel('Nhóm Cholesterol (mg/dl)')\n",
        "        plt.ylabel('Tỉ lệ mắc bệnh tim')\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'visualizations/{dataset_name}_chol_disease_trend.png')\n",
        "        plt.show()\n",
        "\n",
        "# Vẽ line charts cho từng tập dữ liệu\n",
        "print(\"Biểu đồ Line Chart cho tập dữ liệu Heart:\")\n",
        "plot_line_charts(heart_df, 'heart')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nBiểu đồ Line Chart cho tập dữ liệu Cleveland:\")\n",
        "plot_line_charts(cleveland_df, 'cleveland')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nBiểu đồ Line Chart cho tập dữ liệu UCI:\")\n",
        "plot_line_charts(uci_df, 'uci')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Tiền xử lý dữ liệu\n",
        "\n",
        "Thực hiện tiền xử lý dữ liệu, bao gồm xử lý giá trị thiếu, mã hóa đặc trưng và chuẩn hóa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 3.1 Xử lý giá trị thiếu và chuẩn hóa dữ liệu Heart\n",
        "\n",
        "def preprocess_heart_data(df):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu từ tập Heart\n",
        "    \"\"\"\n",
        "    print(\"Đang xử lý dữ liệu Heart...\")\n",
        "    \n",
        "    # Tạo bản sao để không ảnh hưởng đến dữ liệu gốc\n",
        "    data = df.copy()\n",
        "    \n",
        "    # Kiểm tra và xử lý giá trị thiếu\n",
        "    if data.isnull().sum().sum() > 0:\n",
        "        print(\"Đang xử lý giá trị thiếu...\")\n",
        "        numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "        numeric_imputer = SimpleImputer(strategy='median')\n",
        "        data[numeric_features] = numeric_imputer.fit_transform(data[numeric_features])\n",
        "    else:\n",
        "        print(\"Không có giá trị thiếu trong dữ liệu Heart\")\n",
        "    \n",
        "    # Chuẩn hóa các đặc trưng số\n",
        "    print(\"Đang chuẩn hóa các đặc trưng số...\")\n",
        "    features = data.drop('target', axis=1)\n",
        "    target = data['target']\n",
        "    \n",
        "    # Hiển thị thông tin về đặc trưng và nhãn\n",
        "    print(f\"\\nSố lượng mẫu: {data.shape[0]}\")\n",
        "    print(f\"Số lượng đặc trưng: {features.shape[1]}\")\n",
        "    print(f\"Phân bố nhãn: {target.value_counts().to_dict()}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Xử lý dữ liệu Heart\n",
        "heart_processed = preprocess_heart_data(heart_df)\n",
        "print(\"\\nDữ liệu Heart sau khi tiền xử lý:\")\n",
        "display(heart_processed.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 3.2 Xử lý giá trị thiếu và chuẩn hóa dữ liệu Cleveland\n",
        "\n",
        "def preprocess_cleveland_data(df):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu từ tập Cleveland\n",
        "    \"\"\"\n",
        "    print(\"Đang xử lý dữ liệu Cleveland...\")\n",
        "    \n",
        "    # Tạo bản sao để không ảnh hưởng đến dữ liệu gốc\n",
        "    data = df.copy()\n",
        "    \n",
        "    # Đổi tên cột condition thành target cho thống nhất (nếu có)\n",
        "    if 'condition' in data.columns:\n",
        "        data.rename(columns={'condition': 'target'}, inplace=True)\n",
        "        print(\"Đã đổi tên cột 'condition' thành 'target' để thống nhất\")\n",
        "    \n",
        "    # Chuyển đổi nhãn thành dạng nhị phân (0: không bệnh, 1: có bệnh)\n",
        "    if 'target' in data.columns and data['target'].max() > 1:\n",
        "        print(\"Chuyển đổi nhãn thành dạng nhị phân (0/1)...\")\n",
        "        data['target'] = data['target'].apply(lambda x: 0 if x == 0 else 1)\n",
        "    \n",
        "    # Kiểm tra và xử lý giá trị thiếu\n",
        "    if data.isnull().sum().sum() > 0:\n",
        "        print(\"Đang xử lý giá trị thiếu...\")\n",
        "        numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "        numeric_imputer = SimpleImputer(strategy='median')\n",
        "        data[numeric_features] = numeric_imputer.fit_transform(data[numeric_features])\n",
        "    else:\n",
        "        print(\"Không có giá trị thiếu trong dữ liệu Cleveland\")\n",
        "    \n",
        "    # Hiển thị thông tin về đặc trưng và nhãn\n",
        "    features = data.drop('target', axis=1)\n",
        "    target = data['target']\n",
        "    print(f\"\\nSố lượng mẫu: {data.shape[0]}\")\n",
        "    print(f\"Số lượng đặc trưng: {features.shape[1]}\")\n",
        "    print(f\"Phân bố nhãn: {target.value_counts().to_dict()}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Xử lý dữ liệu Cleveland\n",
        "cleveland_processed = preprocess_cleveland_data(cleveland_df)\n",
        "print(\"\\nDữ liệu Cleveland sau khi tiền xử lý:\")\n",
        "display(cleveland_processed.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 3.3 Xử lý giá trị thiếu và chuẩn hóa dữ liệu UCI\n",
        "\n",
        "def preprocess_uci_data(df):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu từ tập UCI\n",
        "    \"\"\"\n",
        "    print(\"Đang xử lý dữ liệu UCI...\")\n",
        "    \n",
        "    # Tạo bản sao để không ảnh hưởng đến dữ liệu gốc\n",
        "    data = df.copy()\n",
        "    \n",
        "    # Xử lý giá trị thiếu\n",
        "    if data.isnull().sum().sum() > 0:\n",
        "        print(\"Đang xử lý giá trị thiếu...\")\n",
        "        # Xử lý các cột số\n",
        "        numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "        numeric_imputer = SimpleImputer(strategy='median')\n",
        "        data[numeric_features] = numeric_imputer.fit_transform(data[numeric_features])\n",
        "        \n",
        "        # Xử lý các cột phân loại\n",
        "        categorical_features = data.select_dtypes(include=['object']).columns\n",
        "        if len(categorical_features) > 0:\n",
        "            categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "            data[categorical_features] = categorical_imputer.fit_transform(data[categorical_features])\n",
        "            print(f\"Đã xử lý giá trị thiếu trong {len(categorical_features)} cột phân loại\")\n",
        "    else:\n",
        "        print(\"Không có giá trị thiếu trong dữ liệu UCI\")\n",
        "    \n",
        "    # Xử lý cột target (nếu có cột 'num')\n",
        "    if 'num' in data.columns:\n",
        "        # Chuyển thành dạng nhị phân: 0 = không bệnh (0), 1 = có bệnh (1-4)\n",
        "        data['target'] = data['num'].apply(lambda x: 0 if x == 0 else 1)\n",
        "        data = data.drop('num', axis=1)\n",
        "        print(\"Đã tạo cột 'target' từ cột 'num' và chuyển về dạng nhị phân (0/1)\")\n",
        "    \n",
        "    # Loại bỏ các cột không cần thiết\n",
        "    if 'id' in data.columns:\n",
        "        data = data.drop('id', axis=1)\n",
        "        print(\"Đã loại bỏ cột 'id'\")\n",
        "    \n",
        "    # Mã hóa các biến phân loại\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns\n",
        "    if len(categorical_features) > 0:\n",
        "        print(f\"Đang mã hóa {len(categorical_features)} biến phân loại...\")\n",
        "        # One-hot encoding cho các biến phân loại\n",
        "        encoded_data = pd.get_dummies(data[categorical_features], drop_first=True)\n",
        "        \n",
        "        # Loại bỏ các cột phân loại gốc và thêm các cột đã mã hóa\n",
        "        data = data.drop(categorical_features, axis=1)\n",
        "        data = pd.concat([data, encoded_data], axis=1)\n",
        "    \n",
        "    # Hiển thị thông tin về đặc trưng và nhãn\n",
        "    if 'target' in data.columns:\n",
        "        features = data.drop('target', axis=1)\n",
        "        target = data['target']\n",
        "        print(f\"\\nSố lượng mẫu: {data.shape[0]}\")\n",
        "        print(f\"Số lượng đặc trưng: {features.shape[1]}\")\n",
        "        print(f\"Phân bố nhãn: {target.value_counts().to_dict()}\")\n",
        "    else:\n",
        "        print(\"\\nKhông tìm thấy cột 'target' trong dữ liệu UCI sau khi tiền xử lý\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Xử lý dữ liệu UCI\n",
        "uci_processed = preprocess_uci_data(uci_df)\n",
        "print(\"\\nDữ liệu UCI sau khi tiền xử lý:\")\n",
        "display(uci_processed.head())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Chia tập huấn luyện và tập kiểm tra\n",
        "\n",
        "Chia mỗi tập dữ liệu thành tập huấn luyện và tập kiểm tra với tỷ lệ 80% - 20%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_and_scale_data(df, dataset_name):\n",
        "    \"\"\"\n",
        "    Chia dữ liệu thành tập huấn luyện và tập kiểm tra, sau đó chuẩn hóa\n",
        "    \"\"\"\n",
        "    print(f\"Đang chia và chuẩn hóa dữ liệu {dataset_name}...\")\n",
        "    \n",
        "    # Xác định biến đích\n",
        "    if 'target' not in df.columns:\n",
        "        print(f\"Không tìm thấy cột 'target' trong dữ liệu {dataset_name}\")\n",
        "        return None, None, None, None, None\n",
        "    \n",
        "    # Tách đặc trưng và nhãn\n",
        "    X = df.drop('target', axis=1)\n",
        "    y = df['target']\n",
        "    \n",
        "    # Chia thành tập huấn luyện và tập kiểm tra (80% - 20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Chuẩn hóa dữ liệu\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Hiển thị thông tin về kích thước dữ liệu\n",
        "    print(f\"Kích thước tập huấn luyện: {X_train.shape[0]} mẫu, {X_train.shape[1]} đặc trưng\")\n",
        "    print(f\"Kích thước tập kiểm tra: {X_test.shape[0]} mẫu, {X_test.shape[1]} đặc trưng\")\n",
        "    print(f\"Phân bố nhãn tập huấn luyện: {y_train.value_counts().to_dict()}\")\n",
        "    print(f\"Phân bố nhãn tập kiểm tra: {y_test.value_counts().to_dict()}\")\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test, scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chia và chuẩn hóa dữ liệu Heart\n",
        "print(\"=== Chia dữ liệu Heart ===\")\n",
        "heart_X_train, heart_X_test, heart_y_train, heart_y_test, heart_scaler = split_and_scale_data(heart_processed, 'Heart')\n",
        "\n",
        "# Chia và chuẩn hóa dữ liệu Cleveland\n",
        "print(\"\\n=== Chia dữ liệu Cleveland ===\")\n",
        "cleveland_X_train, cleveland_X_test, cleveland_y_train, cleveland_y_test, cleveland_scaler = split_and_scale_data(cleveland_processed, 'Cleveland')\n",
        "\n",
        "# Chia và chuẩn hóa dữ liệu UCI\n",
        "print(\"\\n=== Chia dữ liệu UCI ===\")\n",
        "uci_X_train, uci_X_test, uci_y_train, uci_y_test, uci_scaler = split_and_scale_data(uci_processed, 'UCI')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Trực quan hóa dữ liệu đã chuẩn hóa\n",
        "\n",
        "Vẽ biểu đồ phân bố của dữ liệu sau khi chuẩn hóa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_scaled_data_distribution(X_train_scaled, X_test_scaled, feature_names, dataset_name):\n",
        "    \"\"\"\n",
        "    Vẽ biểu đồ phân bố của dữ liệu đã chuẩn hóa\n",
        "    \"\"\"\n",
        "    # Chọn một số đặc trưng quan trọng để hiển thị\n",
        "    n_features = min(5, len(feature_names))\n",
        "    selected_features = list(range(n_features))\n",
        "    \n",
        "    # Chuyển dữ liệu đã chuẩn hóa về dạng DataFrame để dễ thao tác\n",
        "    X_train_df = pd.DataFrame(X_train_scaled[:, selected_features], columns=feature_names[selected_features])\n",
        "    X_test_df = pd.DataFrame(X_test_scaled[:, selected_features], columns=feature_names[selected_features])\n",
        "    \n",
        "    # Thêm cột để đánh dấu tập dữ liệu\n",
        "    X_train_df['dataset'] = 'Train'\n",
        "    X_test_df['dataset'] = 'Test'\n",
        "    \n",
        "    # Gộp dữ liệu để vẽ biểu đồ\n",
        "    combined_df = pd.concat([X_train_df, X_test_df])\n",
        "    \n",
        "    # Chuyển dữ liệu về dạng \"long form\" để vẽ biểu đồ\n",
        "    melted_df = pd.melt(combined_df, id_vars=['dataset'], var_name='Feature', value_name='Value')\n",
        "    \n",
        "    # Vẽ biểu đồ phân bố\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.boxplot(x='Feature', y='Value', hue='dataset', data=melted_df)\n",
        "    plt.title(f'Phân bố dữ liệu đã chuẩn hóa - {dataset_name}', fontsize=16)\n",
        "    plt.xlabel('Đặc trưng', fontsize=12)\n",
        "    plt.ylabel('Giá trị (đã chuẩn hóa)', fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'visualizations/{dataset_name}_scaled_distribution.png')\n",
        "    plt.show()\n",
        "\n",
        "# Vẽ phân bố dữ liệu đã chuẩn hóa cho tập Heart\n",
        "if heart_X_train is not None and heart_X_test is not None:\n",
        "    heart_feature_names = np.array(heart_processed.drop('target', axis=1).columns)\n",
        "    print(\"Phân bố dữ liệu Heart sau khi chuẩn hóa:\")\n",
        "    plot_scaled_data_distribution(heart_X_train, heart_X_test, heart_feature_names, 'Heart')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vẽ phân bố dữ liệu đã chuẩn hóa cho tập Cleveland\n",
        "if cleveland_X_train is not None and cleveland_X_test is not None:\n",
        "    cleveland_feature_names = np.array(cleveland_processed.drop('target', axis=1).columns)\n",
        "    print(\"\\nPhân bố dữ liệu Cleveland sau khi chuẩn hóa:\")\n",
        "    plot_scaled_data_distribution(cleveland_X_train, cleveland_X_test, cleveland_feature_names, 'Cleveland')\n",
        "\n",
        "# Vẽ phân bố dữ liệu đã chuẩn hóa cho tập UCI\n",
        "if uci_X_train is not None and uci_X_test is not None:\n",
        "    uci_feature_names = np.array(uci_processed.drop('target', axis=1).columns)\n",
        "    print(\"\\nPhân bố dữ liệu UCI sau khi chuẩn hóa:\")\n",
        "    plot_scaled_data_distribution(uci_X_train, uci_X_test, uci_feature_names, 'UCI')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Kết hợp dữ liệu\n",
        "\n",
        "Kết hợp dữ liệu từ các nguồn khác nhau để tạo tập dữ liệu lớn hơn.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def combine_datasets(datasets, dataset_names):\n",
        "    \"\"\"\n",
        "    Kết hợp nhiều tập dữ liệu thành một\n",
        "    \"\"\"\n",
        "    # Kiểm tra xem có đủ dữ liệu không\n",
        "    if len(datasets) < 2:\n",
        "        print(\"Cần ít nhất 2 tập dữ liệu để kết hợp\")\n",
        "        return None\n",
        "    \n",
        "    # Tìm các cột chung giữa các tập dữ liệu\n",
        "    common_columns = set.intersection(*[set(df.columns) for df in datasets])\n",
        "    \n",
        "    # Kiểm tra xem có cột 'target' không\n",
        "    if 'target' not in common_columns:\n",
        "        print(\"Cột 'target' không có trong tất cả các tập dữ liệu, không thể kết hợp!\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"Các cột chung giữa các tập dữ liệu: {common_columns}\")\n",
        "    \n",
        "    # Chỉ giữ lại các cột chung và kết hợp dữ liệu\n",
        "    combined_data = pd.concat([df[list(common_columns)] for df in datasets], ignore_index=True)\n",
        "    \n",
        "    # Thêm cột để đánh dấu nguồn dữ liệu\n",
        "    for i, (df, name) in enumerate(zip(datasets, dataset_names)):\n",
        "        combined_data.loc[combined_data.index.isin(range(len(combined_data) - len(df), len(combined_data))), 'source'] = name\n",
        "    \n",
        "    print(f\"Đã kết hợp {len(datasets)} tập dữ liệu với {combined_data.shape[0]} mẫu và {len(common_columns)} đặc trưng chung\")\n",
        "    \n",
        "    return combined_data\n",
        "\n",
        "# Thử kết hợp các tập dữ liệu\n",
        "datasets_to_combine = []\n",
        "dataset_names = []\n",
        "\n",
        "if 'target' in heart_processed.columns:\n",
        "    datasets_to_combine.append(heart_processed)\n",
        "    dataset_names.append('Heart')\n",
        "\n",
        "if 'target' in cleveland_processed.columns:\n",
        "    datasets_to_combine.append(cleveland_processed)\n",
        "    dataset_names.append('Cleveland')\n",
        "\n",
        "print(\"Kết hợp dữ liệu từ các nguồn...\")\n",
        "combined_df = combine_datasets(datasets_to_combine, dataset_names)\n",
        "\n",
        "if combined_df is not None:\n",
        "    print(\"\\nDữ liệu sau khi kết hợp:\")\n",
        "    display(combined_df.head())\n",
        "    \n",
        "    # Trực quan hóa dữ liệu kết hợp\n",
        "    print(\"\\nTrực quan hóa dữ liệu kết hợp:\")\n",
        "    plot_histograms(combined_df, 'combined')\n",
        "    plot_correlation_matrix(combined_df, 'combined')\n",
        "    \n",
        "    # Chia dữ liệu kết hợp\n",
        "    print(\"\\n=== Chia dữ liệu kết hợp ===\")\n",
        "    combined_X_train, combined_X_test, combined_y_train, combined_y_test, combined_scaler = split_and_scale_data(combined_df, 'Combined')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Lưu dữ liệu đã xử lý\n",
        "\n",
        "Lưu các tập dữ liệu đã xử lý để sử dụng cho bước huấn luyện mô hình.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_processed_data(X_train, X_test, y_train, y_test, dataset_name):\n",
        "    \"\"\"\n",
        "    Lưu dữ liệu đã xử lý vào thư mục processed_data\n",
        "    \"\"\"\n",
        "    if X_train is None or X_test is None or y_train is None or y_test is None:\n",
        "        print(f\"Không thể lưu dữ liệu {dataset_name} do thiếu dữ liệu\")\n",
        "        return\n",
        "    \n",
        "    # Tạo thư mục nếu chưa tồn tại\n",
        "    if not os.path.exists('processed_data'):\n",
        "        os.makedirs('processed_data')\n",
        "    \n",
        "    # Lưu dữ liệu\n",
        "    np.save(f'processed_data/{dataset_name.lower()}_X_train.npy', X_train)\n",
        "    np.save(f'processed_data/{dataset_name.lower()}_X_test.npy', X_test)\n",
        "    np.save(f'processed_data/{dataset_name.lower()}_y_train.npy', y_train)\n",
        "    np.save(f'processed_data/{dataset_name.lower()}_y_test.npy', y_test)\n",
        "    \n",
        "    print(f\"Đã lưu dữ liệu {dataset_name} vào thư mục processed_data\")\n",
        "\n",
        "# Lưu dữ liệu Heart\n",
        "save_processed_data(heart_X_train, heart_X_test, heart_y_train, heart_y_test, 'heart')\n",
        "\n",
        "# Lưu dữ liệu Cleveland\n",
        "save_processed_data(cleveland_X_train, cleveland_X_test, cleveland_y_train, cleveland_y_test, 'cleveland')\n",
        "\n",
        "# Lưu dữ liệu UCI\n",
        "save_processed_data(uci_X_train, uci_X_test, uci_y_train, uci_y_test, 'uci')\n",
        "\n",
        "# Lưu dữ liệu Combined (nếu có)\n",
        "if 'combined_X_train' in locals() and combined_X_train is not None:\n",
        "    save_processed_data(combined_X_train, combined_X_test, combined_y_train, combined_y_test, 'combined')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Tổng kết\n",
        "\n",
        "Tổng kết quá trình tiền xử lý dữ liệu và các phát hiện chính.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Thống kê về các tập dữ liệu\n",
        "data_stats = pd.DataFrame({\n",
        "    'Tập dữ liệu': ['Heart', 'Cleveland', 'UCI', 'Combined'],\n",
        "    'Số lượng mẫu': [\n",
        "        heart_processed.shape[0] if 'heart_processed' in locals() else 0,\n",
        "        cleveland_processed.shape[0] if 'cleveland_processed' in locals() else 0,\n",
        "        uci_processed.shape[0] if 'uci_processed' in locals() else 0,\n",
        "        combined_df.shape[0] if 'combined_df' in locals() else 0\n",
        "    ],\n",
        "    'Số lượng đặc trưng': [\n",
        "        heart_processed.shape[1] - 1 if 'heart_processed' in locals() else 0,  # Trừ đi cột target\n",
        "        cleveland_processed.shape[1] - 1 if 'cleveland_processed' in locals() else 0,\n",
        "        uci_processed.shape[1] - 1 if 'uci_processed' in locals() else 0,\n",
        "        combined_df.shape[1] - 1 if 'combined_df' in locals() else 0\n",
        "    ],\n",
        "    'Tỷ lệ mắc bệnh': [\n",
        "        heart_processed['target'].mean() if 'heart_processed' in locals() else 0,\n",
        "        cleveland_processed['target'].mean() if 'cleveland_processed' in locals() else 0,\n",
        "        uci_processed['target'].mean() if 'uci_processed' in locals() else 0,\n",
        "        combined_df['target'].mean() if 'combined_df' in locals() else 0\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Hiển thị bảng thống kê\n",
        "print(\"Tổng kết về các tập dữ liệu:\")\n",
        "display(data_stats)\n",
        "\n",
        "# Tạo biểu đồ so sánh\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Tập dữ liệu', y='Số lượng mẫu', data=data_stats)\n",
        "plt.title('So sánh kích thước các tập dữ liệu', fontsize=16)\n",
        "plt.ylabel('Số lượng mẫu')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.savefig('visualizations/datasets_size_comparison.png')\n",
        "plt.show()\n",
        "\n",
        "# Vẽ biểu đồ tỷ lệ mắc bệnh\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Tập dữ liệu', y='Tỷ lệ mắc bệnh', data=data_stats)\n",
        "plt.title('So sánh tỷ lệ mắc bệnh giữa các tập dữ liệu', fontsize=16)\n",
        "plt.ylabel('Tỷ lệ mắc bệnh (%)')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.savefig('visualizations/disease_rate_comparison.png')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nQuá trình tiền xử lý dữ liệu đã hoàn tất!\")\n",
        "print(\"- Dữ liệu đã được làm sạch, xử lý giá trị thiếu và chuẩn hóa\")\n",
        "print(\"- Đã chia tập dữ liệu thành tập huấn luyện (80%) và tập kiểm tra (20%)\")\n",
        "print(\"- Các tập dữ liệu đã được lưu vào thư mục processed_data để sử dụng cho việc huấn luyện mô hình\")\n",
        "print(\"- Các biểu đồ trực quan hóa đã được lưu vào thư mục visualizations\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
